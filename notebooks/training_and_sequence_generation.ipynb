{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_QqB7EQOYi4"
      },
      "source": [
        "# Cloning repository and installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-rPa178i9Bwh",
        "outputId": "a09bdb30-fbb0-44f7-9dd1-c522ae505837"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/pinellolab/DNA-Diffusion.git && cd DNA-Diffusion && uv sync"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYeWyznJAkKA",
        "outputId": "97638525-c707-4fe4-a693-2dec74172e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DNA-Diffusion\n"
          ]
        }
      ],
      "source": [
        "%cd DNA-Diffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOv6pRP4_f41"
      },
      "source": [
        "# Basic Training Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYDLoBS9__IH"
      },
      "source": [
        "Below we provide an example of the training using the debug flag. This will only train the model on a single sequence for a minimum of 5 epochs with a patience parameter of 2 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArMTlzed_V-E",
        "outputId": "aa107ea1-945f-4be0-da07-60ac9a8ead1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model:\n",
            "  _target_: src.dnadiffusion.models.unet.UNet\n",
            "  dim: 200\n",
            "  channels: 1\n",
            "  dim_mults:\n",
            "  - 1\n",
            "  - 2\n",
            "  - 4\n",
            "  resnet_block_groups: 4\n",
            "data:\n",
            "  _target_: src.dnadiffusion.data.dataloader.get_dataset\n",
            "  data_path: data/K562_hESCT0_HepG2_GM12878_12k_sequences_per_group.txt\n",
            "  saved_data_path: data/encode_data.pkl\n",
            "  load_saved_data: true\n",
            "  debug: true\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.0001\n",
            "diffusion:\n",
            "  _target_: src.dnadiffusion.models.diffusion.Diffusion\n",
            "  timesteps: 50\n",
            "  beta_start: 0.0001\n",
            "  beta_end: 0.2\n",
            "training:\n",
            "  distributed: false\n",
            "  precision: float32\n",
            "  num_workers: 1\n",
            "  pin_memory: false\n",
            "  batch_size: 1\n",
            "  sample_batch_size: 1\n",
            "  num_epochs: 2200\n",
            "  min_epochs: 5\n",
            "  patience: 2\n",
            "  log_step: 50\n",
            "  sample_epoch: 50000\n",
            "  number_of_samples: 10\n",
            "  use_wandb: false\n",
            "\n",
            "  0% 0/2200 [00:00<?, ?it/s]/content/DNA-Diffusion/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "  0% 6/2200 [01:14<5:18:05,  8.70s/it]Early stopping at epoch 6, Best val loss: 0.28959813714027405 achieved at epoch 4\n",
            "  0% 6/2200 [01:15<7:37:23, 12.51s/it]\n"
          ]
        }
      ],
      "source": [
        "!uv run train.py -cn train_debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ql3m5jQAv-F"
      },
      "source": [
        "# Basic sequence generation example using the created checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgbgEGD0AwuL"
      },
      "source": [
        "The model successfully trained and now we will use the checkpoint with the lowest validation loss to generate 1 sequence per cell type. Given that the training seed is not fixed, this is not a deterministic result and your validation loss may slightly vary from the cached example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_CWe2ij2ZK5",
        "outputId": "f8a5a3e6-d52d-4d77-e137-2cb8a721b131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All available checkpoints: \n",
            "['checkpoints/model_epoch2_step3_valloss_0.348331.pt', 'checkpoints/model_epoch4_step5_valloss_0.289598.pt']\n",
            "\n",
            "Using checkpoint with lowest validation loss: \n",
            "checkpoints/model_epoch4_step5_valloss_0.289598.pt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "files = os.listdir(checkpoint_dir)\n",
        "file_paths = sorted([os.path.join(checkpoint_dir, f) for f in files if os.path.isfile(os.path.join(checkpoint_dir, f)) and \".gitkeep\" not in f])\n",
        "best_checkpoint = file_paths[-1]\n",
        "\n",
        "print(f\"All available checkpoints: \\n{file_paths}\")\n",
        "print(f\"\\nUsing checkpoint with lowest validation loss: \\n{best_checkpoint}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q45JZoaAsMw",
        "outputId": "3ec266b9-c00a-4c52-cea2-8d02e58f6be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model:\n",
            "  _target_: src.dnadiffusion.models.unet.UNet\n",
            "  dim: 200\n",
            "  channels: 1\n",
            "  dim_mults:\n",
            "  - 1\n",
            "  - 2\n",
            "  - 4\n",
            "  resnet_block_groups: 4\n",
            "data:\n",
            "  _target_: src.dnadiffusion.data.dataloader.get_dataset_for_sampling\n",
            "  data_path: data/K562_hESCT0_HepG2_GM12878_12k_sequences_per_group.txt\n",
            "  saved_data_path: data/encode_data.pkl\n",
            "  load_saved_data: true\n",
            "  debug: false\n",
            "  cell_types: null\n",
            "diffusion:\n",
            "  _target_: src.dnadiffusion.models.diffusion.Diffusion\n",
            "  timesteps: 50\n",
            "  beta_start: 0.0001\n",
            "  beta_end: 0.2\n",
            "sampling:\n",
            "  checkpoint_path: checkpoints/model_epoch4_step5_valloss_0.289598.pt\n",
            "  sample_batch_size: 1\n",
            "  number_of_samples: 1\n",
            "  guidance_scale: 1.0\n",
            "\n",
            "Loading checkpoint\n",
            "Model sent to cuda\n",
            "Found cell types: ['GM12878_ENCLB441ZZZ', 'HepG2_ENCLB029COU', 'K562_ENCLB843GMH', 'hESCT0_ENCLB449ZZZ']\n",
            "Generating 1 samples for cell GM12878_ENCLB441ZZZ\n",
            "100% 1/1 [00:02<00:00,  2.14s/it]\n",
            "Generating 1 samples for cell HepG2_ENCLB029COU\n",
            "100% 1/1 [00:01<00:00,  1.68s/it]\n",
            "Generating 1 samples for cell K562_ENCLB843GMH\n",
            "100% 1/1 [00:01<00:00,  1.68s/it]\n",
            "Generating 1 samples for cell hESCT0_ENCLB449ZZZ\n",
            "100% 1/1 [00:01<00:00,  1.68s/it]\n"
          ]
        }
      ],
      "source": [
        "!uv run sample.py sampling.number_of_samples=1 sampling.sample_batch_size=1 sampling.checkpoint_path=$best_checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HJm-9OJC49v"
      },
      "source": [
        "# View Generated Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-NmKG6FC6Pi",
        "outputId": "eb29f0f1-76ba-4aa4-94d2-638c3f6fc129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Displaying sequences from: data/outputs\n",
            "\n",
            "--- Cell Type: GM12878 (GM12878_ENCLB441ZZZ.txt) ---\n",
            "CAACAAAGTAAAATCGAATAATAAGGCCGCCCTGACCCCAAAGAGAACCTAAAACCAAAACCAATTTTACAAACACCCAAGTTTCCTTCCAACGCGCCGAAAAAATATATTAAGCTTAAGAACACCAAAGAGTCGTTGACAAGCGCCTTTTATCAGACAACGCCCTACCCAAGACTAACGATAATAAAGTGCGAAGAAGG\n",
            "-------------------------\n",
            "\n",
            "--- Cell Type: HepG2 (HepG2_ENCLB029COU.txt) ---\n",
            "AAAGGACAGAACAACTGGTTTTTCTTTAGGTCATTAGGCCCGTTCAAAGAGGAACACAACCACCCGGGGCGCAAAAAAAATTACCCCAGTAGTTGCCAAATCTCTCAATGTCCTTGATACCCACTCCGAGATCCGGGGATGAAAGAACTGGCAGGTTGGGAGAAAAGACCACGGCAATCTGCGCCACAATAATATTCTAT\n",
            "-----------------------\n",
            "\n",
            "--- Cell Type: K562 (K562_ENCLB843GMH.txt) ---\n",
            "GAGGAGCTAAAACTAATGTGACGCCCGACCAAGTGGCACATCATAAAGGATGTTCGCAATTTACCAATGCCACCCAAAAATGATGAGAACTATTCGCCTCCACTGACGAAACTTCACAAGAGTTCCTTATGAAAGTTTTGCAAAAGCAAGCGCCCCGCCGGGTTTCATCTGCCAACCCACACCCGAAAGAAAAACACAAG\n",
            "----------------------\n",
            "\n",
            "--- Cell Type: hESCT0 (hESCT0_ENCLB449ZZZ.txt) ---\n",
            "GAAAGATGTTGTAAAGGGCCAACAACAGATCTCCATACCTTAAGAAGTTAGGAAAATGGGTGAGATGATGAGCGATTTGGGAGGCAAACCACAAACGGTTCGCTGATTTACTATGTAAAGGCCAACGCCCTAAGTGAAAAAAGCCCACCGCTGAGATCAAACTAAAATTTTGGTCTCCTCCCCCTACCTCGAGACGGAAT\n",
            "------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "def display_sequences(output_dir=\"data/outputs\"):\n",
        "    if not os.path.isdir(output_dir):\n",
        "        print(f\"Error: Directory '{output_dir}' not found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Displaying sequences from: {output_dir}\\n\")\n",
        "\n",
        "    for filename in sorted(os.listdir(output_dir)):\n",
        "        filepath = os.path.join(output_dir, filename)\n",
        "\n",
        "        if os.path.isfile(filepath) and \"gitkeep\" not in filepath:\n",
        "          cell_type = filename.split('_')[0]\n",
        "          print(f\"--- Cell Type: {cell_type} ({filename}) ---\")\n",
        "          result = subprocess.run(['cat', filepath], capture_output=True, text=True, check=True)\n",
        "          print(result.stdout)\n",
        "          print(\"-\" * (len(cell_type) + 18) + \"\\n\")\n",
        "\n",
        "display_sequences()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wawDHcmnDPoa"
      },
      "source": [
        "To see an example of sequence generation using our trained checkpoint checkout the example listed in the README"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
